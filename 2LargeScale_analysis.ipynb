{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STRINGS TO HASHES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"I have a dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7562983679033046312"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find hash for the word \"cat\"\n",
    "dog_hash = nlp.vocab.strings['dog']\n",
    "dog_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dog'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find cat_hash variable to the the sting \n",
    "dog_string = nlp.vocab.strings[dog_hash]\n",
    "dog_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lookup labeled \"person\" to get hash\n",
    "words = nlp(\"David Bowie is a PERSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "380"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person_hash = nlp.vocab.strings['PERSON']\n",
    "person_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PERSON'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person_string = nlp.vocab.strings[person_hash]\n",
    "person_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DOC | SPAN | TOKEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating a document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create doc from scratch \n",
    "import spacy \n",
    "from spacy.tokens import Doc\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spaCy is cool!'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sent should equal \"spaCy is cool!\"\n",
    "words = [\"spaCy\", \"is\", 'cool', '!']\n",
    "spaces = [True, True, False, False]\n",
    "\n",
    "#create a Doc from words and spaces\n",
    "doc = Doc(nlp.vocab, words=words, spaces=spaces)\n",
    "doc.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Go, get started!'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_ = ['Go', ',', 'get', 'started', '!']\n",
    "spaces_ = [False, True, True, False, False]\n",
    "\n",
    "doc_ = Doc(nlp.vocab, words=words_, spaces=spaces_)\n",
    "doc_.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Oh, really?'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = ['Oh', ',', 'really', '?']\n",
    "space = [False, True, False, False]\n",
    "\n",
    "docu = Doc(nlp.vocab, words=sent, spaces=space)\n",
    "docu.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating docs & SPANS mannually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DOC &  SPAN \n",
    "from spacy.lang.en import English\n",
    "from spacy.tokens import Doc, Span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLP = English()\n",
    "\n",
    "words3 = ['I', 'like', 'David', 'Bowie']\n",
    "spaces3 = [True, True, True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I like David Bowie'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a doc\n",
    "doc3 = Doc(nlp.vocab, words=words3, spaces=spaces3)\n",
    "doc3.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "David Bowie PERSON\n"
     ]
    }
   ],
   "source": [
    "#create span for \"David bowie\" and assign label PERSON\n",
    "span = Span(doc3, 2, 4, label='PERSON')\n",
    "print(span.text, span.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the span to the doc\n",
    "doc3.ents = [span]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('David Bowie', 380)]\n"
     ]
    }
   ],
   "source": [
    "print([(ent.text, ent.label) for ent in doc3.ents])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WORD VECTORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "from spacy.lang.en import English\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.2009e-01, -3.0322e-02, -7.9859e-02, -4.6279e-01, -3.8600e-01,\n",
       "        3.6962e-01, -7.7178e-01, -1.1529e-01,  3.3601e-02,  5.6573e-01,\n",
       "       -2.4001e-01,  4.1833e-01,  1.5049e-01,  3.5621e-01, -2.1508e-01,\n",
       "       -4.2743e-01,  8.1400e-02,  3.3916e-01,  2.1637e-01,  1.4792e-01,\n",
       "        4.5811e-01,  2.0966e-01, -3.5706e-01,  2.3800e-01,  2.7971e-02,\n",
       "       -8.4538e-01,  4.1917e-01, -3.9181e-01,  4.0434e-04, -1.0662e+00,\n",
       "        1.4591e-01,  1.4643e-03,  5.1277e-01,  2.6072e-01,  8.3785e-02,\n",
       "        3.0340e-01,  1.8579e-01,  5.9999e-02, -4.0270e-01,  5.0888e-01,\n",
       "       -1.1358e-01, -2.8854e-01, -2.7068e-01,  1.1017e-02, -2.2217e-01,\n",
       "        6.9076e-01,  3.6459e-02,  3.0394e-01,  5.6989e-02,  2.2733e-01,\n",
       "       -9.9473e-02,  1.5165e-01,  1.3540e-01, -2.4965e-01,  9.8078e-01,\n",
       "       -8.0492e-01,  1.9326e-01,  3.1128e-01,  5.5390e-02, -4.2423e-01,\n",
       "       -1.4082e-02,  1.2708e-01,  1.8868e-01,  5.9777e-02, -2.2215e-01,\n",
       "       -8.3950e-01,  9.1987e-02,  1.0180e-01, -3.1299e-01,  5.5083e-01,\n",
       "       -3.0717e-01,  4.4201e-01,  1.2666e-01,  3.7643e-01,  3.2333e-01,\n",
       "        9.5673e-02,  2.5083e-01, -6.4049e-02,  4.2143e-01, -1.9375e-01,\n",
       "        3.8026e-01,  7.0883e-03, -2.0371e-01,  1.5402e-01, -3.7877e-03,\n",
       "       -2.9396e-01,  9.6518e-01,  2.0068e-01, -5.6572e-01, -2.2581e-01,\n",
       "        3.2251e-01, -3.4634e-01,  2.7064e-01, -2.0687e-01, -4.7229e-01,\n",
       "        3.1704e-01, -3.4665e-01, -2.5188e-01, -1.1201e-01, -3.3937e-01,\n",
       "        3.1518e-01, -3.2221e-01, -2.4530e-01, -7.1571e-02, -4.3971e-01,\n",
       "       -1.2070e+00,  3.3365e-01, -5.8208e-02,  8.0899e-01,  4.2335e-01,\n",
       "        3.8678e-01, -6.0797e-01, -7.3760e-01, -2.0547e-01, -1.7499e-01,\n",
       "       -3.7842e-03,  2.1930e-01, -5.2486e-02,  3.4869e-01,  4.3852e-01,\n",
       "       -3.4471e-01,  2.8910e-01,  7.2554e-02, -4.8625e-01, -3.8390e-01,\n",
       "       -4.4760e-01,  4.3278e-01, -2.7128e-03, -9.0067e-01, -3.0819e-02,\n",
       "       -3.8630e-01, -8.0798e-02, -1.6243e-01,  2.8830e-01, -2.6349e-01,\n",
       "        1.7628e-01,  3.5958e-01,  5.7672e-01, -5.4624e-01,  3.8555e-02,\n",
       "       -2.0182e+00,  3.2916e-01,  3.4672e-01,  1.5398e-01, -4.3446e-01,\n",
       "       -4.1428e-02, -6.9588e-02,  5.1513e-01, -1.3489e-01, -5.7239e-02,\n",
       "        4.9241e-01,  1.8643e-01,  3.8596e-01, -3.7329e-02, -5.4216e-01,\n",
       "       -1.8152e-01,  4.3110e-01, -4.6967e-01,  6.6801e-02,  5.0323e-01,\n",
       "       -2.4059e-01,  3.6742e-01,  2.9300e-01, -8.7883e-02, -4.7940e-01,\n",
       "       -4.3431e-02, -2.6137e-01, -6.2658e-01,  1.1446e-01,  2.7682e-01,\n",
       "        3.4800e-01,  5.0018e-01,  1.4269e-01, -3.3545e-01, -3.9712e-01,\n",
       "       -3.3121e-01, -3.4434e-01, -4.1627e-01, -3.5707e-03, -6.2350e-01,\n",
       "        3.7794e-01, -1.6765e-01, -4.1954e-01, -3.3134e-01,  3.1232e-01,\n",
       "       -3.9494e-01, -4.6921e-03, -4.8884e-01, -2.2059e-02, -2.6174e-01,\n",
       "        1.7937e-01,  3.6628e-01,  5.8971e-02, -3.5991e-01, -4.4393e-01,\n",
       "       -1.1890e-01,  3.3487e-01,  3.6505e-02, -3.2788e-01,  3.3425e-01,\n",
       "       -5.6361e-01, -1.1190e-01,  5.3770e-01,  2.0311e-01,  1.5110e-01,\n",
       "        1.0623e-02,  3.3401e-01,  4.6084e-01,  5.6293e-01, -7.5432e-02,\n",
       "        5.4813e-01,  1.9395e-01, -2.6265e-01, -3.1699e-01, -8.1778e-01,\n",
       "        5.8169e-02, -5.7866e-02, -1.1781e-01, -5.8742e-02, -1.4092e-01,\n",
       "       -9.9394e-01, -9.4532e-02,  2.3503e-01, -4.9027e-01,  8.5832e-01,\n",
       "        1.1540e-01, -1.5049e-01,  1.9065e-01, -2.6705e-01,  2.5326e-01,\n",
       "       -6.7579e-01, -1.0633e-02, -5.5158e-02, -3.1004e-01, -5.8036e-02,\n",
       "       -1.7200e-01,  1.3298e-01, -3.2899e-01, -7.5481e-02,  2.9425e-02,\n",
       "       -3.2949e-01, -1.8691e-01, -9.5323e-01, -3.5468e-01, -3.3162e-01,\n",
       "        5.6441e-02,  2.1790e-02,  1.7182e-01, -4.4267e-01,  6.9765e-01,\n",
       "       -2.6876e-01,  1.1659e-01, -1.6584e-01,  3.8296e-01,  2.9109e-01,\n",
       "        3.6318e-01,  3.6961e-01,  1.6305e-01,  1.8152e-01,  2.2453e-01,\n",
       "        3.9866e-02, -3.7607e-02, -3.6089e-01,  7.0818e-02, -2.1509e-01,\n",
       "        3.6551e-01, -5.1603e-01, -5.8102e-03, -4.8320e-01, -2.5068e-01,\n",
       "       -5.2062e-02, -2.0828e-01,  2.9060e-01,  2.2084e-02, -6.8123e-01,\n",
       "        4.2063e-01,  9.5973e-02,  8.1720e-01, -1.5241e-01,  6.2994e-01,\n",
       "        2.6449e-01, -1.3516e-01,  3.2450e-01,  3.0503e-01,  1.2357e-01,\n",
       "        1.5107e-01,  2.8327e-01, -3.3838e-01,  4.6106e-02, -1.2361e-01,\n",
       "        1.4516e-01, -2.7947e-02,  2.6231e-02, -5.9591e-01, -4.4183e-01,\n",
       "        7.8440e-01, -3.4375e-02, -1.3928e+00,  3.5248e-01,  6.5220e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#process text\n",
    "document = nlp(\"Two bananas in pyjamas\")\n",
    "\n",
    "#get vector for the token = \"bananas\"\n",
    "bananas_vector = document[1].vector\n",
    "bananas_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMPARING SIMILARITIES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "summer1 = nlp(\"It's a warm summer day\")\n",
    "summer2 = nlp(\"cold and rainy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7787822684387955"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the similarity of the two docs \n",
    "sims = summer1.similarity(summer2)\n",
    "sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_a = nlp('''Regulation A is an exemption from registration for public offerings. Regulation A has two offering tiers: Tier 1, for offerings of up to $20 million in a \n",
    "12-month period; and Tier 2, for offerings of up to $50 million in a 12-month period. For offerings of up to $20 million, companies can elect to proceed under \n",
    "the requirements for either Tier 1 or Tier 2. There are certain basic requirements applicable to both Tier 1 and Tier 2 offerings, including company eligibility \n",
    "requirements, bad actor disqualification provisions, disclosure, and other matters. Additional requirements apply to Tier 2 offerings, including limitations on \n",
    "the amount of money a non-accredited investor may invest in a Tier 2 offering, requirements for audited financial statements and the filing of ongoing reports. \n",
    "Issuers in Tier 2 offerings are not required to register or qualify their offerings with state securities regulators.''')\n",
    "\n",
    "reg_d = nlp('''FESTUS, Miss. (FOX 13) - One café put a major twist on a classic ice cream sundae by introduced: pickle splits. The Pine Mountain Country Coffee House in Festus, \n",
    "Missouri simply replaced the banana in a banana split with a pickle. The owner of the café said she first tried the combination back when she was younger. It started \n",
    "as a “dare” but she ended up liking it. CONTINUE READING BELOW It wasn’t until her husband teased her into putting it on the menu that her pickle passion was made \n",
    "public. The dish comes with vanilla, strawberry and chocolate ice cream. All topped with whipped cream, cherries and, of course, pickle spears.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8085691837631346"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ge the similarity of doc_one and doc_two \n",
    "similarity = reg_a.similarity(reg_d)\n",
    "similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Token Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1346367"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokes = nlp(\"keyboard and pizza\")\n",
    "token1, token2 = tokes[0], tokes[2]\n",
    "\n",
    "#get similarity of tokens\n",
    "similarities = token1.similarity(token2)\n",
    "similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SPAN similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7517392"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spansent = nlp(\"This was a great restaurant. Afterwards, we went to a really nice bar.\")\n",
    "\n",
    "#create spans\n",
    "span1 = spansent[3:5]\n",
    "span2 = spansent[12:15]\n",
    "\n",
    "#get similarity \n",
    "span_sims = span1.similarity(span2)\n",
    "span_sims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEBUGGING PATTERNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase = \"Twitch Prime, the perks program for Amazon Prime members offering free loot, games and other benefits, is ditching one of its best features: ad-free viewing. According to an email sent out to Amazon Prime members today, ad-free viewing will no longer be included as a part of Twitch Prime for new members, beginning on September 14. However, members with existing annual subscriptions will be able to continue to enjoy ad-free viewing until their subscription comes up for renewal. Those with monthly subscriptions will have access to ad-free viewing until October 15.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATTERN1 Amazon Prime\n",
      "PATTERN2 ad-free viewing\n",
      "PATTERN1 Amazon Prime\n",
      "PATTERN2 ad-free viewing\n",
      "PATTERN2 ad-free viewing\n",
      "PATTERN2 ad-free viewing\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(phrase)\n",
    "# Create the match patterns\n",
    "pattern1 = [{'LOWER': 'amazon'}, {'IS_TITLE': True, 'POS': 'PROPN'}]\n",
    "pattern2 = [{'LOWER': 'ad'},{\"TEXT\": '-'}, {\"LOWER\": \"free\"}, {'POS': 'NOUN'}]\n",
    "\n",
    "# Initialize the Matcher and add the patterns\n",
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add('PATTERN1', None, pattern1)\n",
    "matcher.add('PATTERN2', None, pattern2)\n",
    "\n",
    "# Iterate over the matches\n",
    "for match_id, start, end in matcher(doc):\n",
    "    # Print pattern string name and text of matched span\n",
    "    print(doc.vocab.strings[match_id], doc[start:end].text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EFFICIENT PHRASE MATCHING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of countries is loaded below as COUNTRIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNTRIES = \"\"\"Afghanistan',\n",
    " 'Åland Islands',\n",
    " 'Albania',\n",
    " 'Algeria',\n",
    " 'American Samoa',\n",
    " 'Andorra',\n",
    " 'Angola',\n",
    " 'Anguilla',\n",
    " 'Antarctica',\n",
    " 'Antigua and Barbuda',\n",
    " 'Argentina',\n",
    " 'Armenia',\n",
    " 'Aruba',\n",
    " 'Australia',\n",
    " 'Austria',\n",
    " 'Azerbaijan',\n",
    " 'Bahamas',\n",
    " 'Bahrain',\n",
    " 'Bangladesh',\n",
    " 'Barbados',\n",
    " 'Belarus',\n",
    " 'Belgium',\n",
    " 'Belize',\n",
    " 'Benin',\n",
    " 'Bermuda',\n",
    " 'Bhutan',\n",
    " 'Bolivia (Plurinational State of)',\n",
    " 'Bonaire, Sint Eustatius and Saba',\n",
    " 'Bosnia and Herzegovina',\n",
    " 'Botswana',\n",
    " 'Bouvet Island',\n",
    " 'Brazil',\n",
    " 'British Indian Ocean Territory',\n",
    " 'United States Minor Outlying Islands',\n",
    " 'Virgin Islands (British)',\n",
    " 'Virgin Islands (U.S.)',\n",
    " 'Brunei Darussalam',\n",
    " 'Bulgaria',\n",
    " 'Burkina Faso',\n",
    " 'Burundi',\n",
    " 'Cambodia',\n",
    " 'Cameroon',\n",
    " 'Canada',\n",
    " 'Cabo Verde',\n",
    " 'Cayman Islands',\n",
    " 'Central African Republic',\n",
    " 'Chad',\n",
    " 'Chile',\n",
    " 'China',\n",
    " 'Christmas Island',\n",
    " 'Cocos (Keeling) Islands',\n",
    " 'Colombia',\n",
    " 'Comoros',\n",
    " 'Congo',\n",
    " 'Congo (Democratic Republic of the)',\n",
    " 'Cook Islands',\n",
    " 'Costa Rica',\n",
    " 'Croatia',\n",
    " 'Cuba',\n",
    " 'Curaçao',\n",
    " 'Cyprus',\n",
    " 'Czech Republic',\n",
    " 'Denmark',\n",
    " 'Djibouti',\n",
    " 'Dominica',\n",
    " 'Dominican Republic',\n",
    " 'Ecuador',\n",
    " 'Egypt',\n",
    " 'El Salvador',\n",
    " 'Equatorial Guinea',\n",
    " 'Eritrea',\n",
    " 'Estonia',\n",
    " 'Ethiopia',\n",
    " 'Falkland Islands (Malvinas)',\n",
    " 'Faroe Islands',\n",
    " 'Fiji',\n",
    " 'Finland',\n",
    " 'France',\n",
    " 'French Guiana',\n",
    " 'French Polynesia',\n",
    " 'French Southern Territories',\n",
    " 'Gabon',\n",
    " 'Gambia',\n",
    " 'Georgia',\n",
    " 'Germany',\n",
    " 'Ghana',\n",
    " 'Gibraltar',\n",
    " 'Greece',\n",
    " 'Greenland',\n",
    " 'Grenada',\n",
    " 'Guadeloupe',\n",
    " 'Guam',\n",
    " 'Guatemala',\n",
    " 'Guernsey',\n",
    " 'Guinea',\n",
    " 'Guinea-Bissau',\n",
    " 'Guyana',\n",
    " 'Haiti',\n",
    " 'Heard Island and McDonald Islands',\n",
    " 'Holy See',\n",
    " 'Honduras',\n",
    " 'Hong Kong',\n",
    " 'Hungary',\n",
    " 'Iceland',\n",
    " 'India',\n",
    " 'Indonesia',\n",
    " \"Côte d'Ivoire\",\n",
    " 'Iran (Islamic Republic of)',\n",
    " 'Iraq',\n",
    " 'Ireland',\n",
    " 'Isle of Man',\n",
    " 'Israel',\n",
    " 'Italy',\n",
    " 'Jamaica',\n",
    " 'Japan',\n",
    " 'Jersey',\n",
    " 'Jordan',\n",
    " 'Kazakhstan',\n",
    " 'Kenya',\n",
    " 'Kiribati',\n",
    " 'Kuwait',\n",
    " 'Kyrgyzstan',\n",
    " \"Lao People's Democratic Republic\",\n",
    " 'Latvia',\n",
    " 'Lebanon',\n",
    " 'Lesotho',\n",
    " 'Liberia',\n",
    " 'Libya',\n",
    " 'Liechtenstein',\n",
    " 'Lithuania',\n",
    " 'Luxembourg',\n",
    " 'Macao',\n",
    " 'Macedonia (the former Yugoslav Republic of)',\n",
    " 'Madagascar',\n",
    " 'Malawi',\n",
    " 'Malaysia',\n",
    " 'Maldives',\n",
    " 'Mali',\n",
    " 'Malta',\n",
    " 'Marshall Islands',\n",
    " 'Martinique',\n",
    " 'Mauritania',\n",
    " 'Mauritius',\n",
    " 'Mayotte',\n",
    " 'Mexico',\n",
    " 'Micronesia (Federated States of)',\n",
    " 'Moldova (Republic of)',\n",
    " 'Monaco',\n",
    " 'Mongolia',\n",
    " 'Montenegro',\n",
    " 'Montserrat',\n",
    " 'Morocco',\n",
    " 'Mozambique',\n",
    " 'Myanmar',\n",
    " 'Namibia',\n",
    " 'Nauru',\n",
    " 'Nepal',\n",
    " 'Netherlands',\n",
    " 'New Caledonia',\n",
    " 'New Zealand',\n",
    " 'Nicaragua',\n",
    " 'Niger',\n",
    " 'Nigeria',\n",
    " 'Niue',\n",
    " 'Norfolk Island',\n",
    " \"Korea (Democratic People's Republic of)\",\n",
    " 'Northern Mariana Islands',\n",
    " 'Norway',\n",
    " 'Oman',\n",
    " 'Pakistan',\n",
    " 'Palau',\n",
    " 'Palestine, State of',\n",
    " 'Panama',\n",
    " 'Papua New Guinea',\n",
    " 'Paraguay',\n",
    " 'Peru',\n",
    " 'Philippines',\n",
    " 'Pitcairn',\n",
    " 'Poland',\n",
    " 'Portugal',\n",
    " 'Puerto Rico',\n",
    " 'Qatar',\n",
    " 'Republic of Kosovo',\n",
    " 'Réunion',\n",
    " 'Romania',\n",
    " 'Russian Federation',\n",
    " 'Rwanda',\n",
    " 'Saint Barthélemy',\n",
    " 'Saint Helena, Ascension and Tristan da Cunha',\n",
    " 'Saint Kitts and Nevis',\n",
    " 'Saint Lucia',\n",
    " 'Saint Martin (French part)',\n",
    " 'Saint Pierre and Miquelon',\n",
    " 'Saint Vincent and the Grenadines',\n",
    " 'Samoa',\n",
    " 'San Marino',\n",
    " 'Sao Tome and Principe',\n",
    " 'Saudi Arabia',\n",
    " 'Senegal',\n",
    " 'Serbia',\n",
    " 'Seychelles',\n",
    " 'Sierra Leone',\n",
    " 'Singapore',\n",
    " 'Sint Maarten (Dutch part)',\n",
    " 'Slovakia',\n",
    " 'Slovenia',\n",
    " 'Solomon Islands',\n",
    " 'Somalia',\n",
    " 'South Africa',\n",
    " 'South Georgia and the South Sandwich Islands',\n",
    " 'Korea (Republic of)',\n",
    " 'South Sudan',\n",
    " 'Spain',\n",
    " 'Sri Lanka',\n",
    " 'Sudan',\n",
    " 'Suriname',\n",
    " 'Svalbard and Jan Mayen',\n",
    " 'Swaziland',\n",
    " 'Sweden',\n",
    " 'Switzerland',\n",
    " 'Syrian Arab Republic',\n",
    " 'Taiwan',\n",
    " 'Tajikistan',\n",
    " 'Tanzania, United Republic of',\n",
    " 'Thailand',\n",
    " 'Timor-Leste',\n",
    " 'Togo',\n",
    " 'Tokelau',\n",
    " 'Tonga',\n",
    " 'Trinidad and Tobago',\n",
    " 'Tunisia',\n",
    " 'Turkey',\n",
    " 'Turkmenistan',\n",
    " 'Turks and Caicos Islands',\n",
    " 'Tuvalu',\n",
    " 'Uganda',\n",
    " 'Ukraine',\n",
    " 'United Arab Emirates',\n",
    " 'United Kingdom of Great Britain and Northern Ireland',\n",
    " 'United States of America',\n",
    " 'Uruguay',\n",
    " 'Uzbekistan',\n",
    " 'Vanuatu',\n",
    " 'Venezuela (Bolivarian Republic of)',\n",
    " 'Viet Nam',\n",
    " 'Wallis and Futuna',\n",
    " 'Western Sahara',\n",
    " 'Yemen',\n",
    " 'Zambia',\n",
    " 'Zimbabwe'\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Czech Republic may help Slovakia protect its airspace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import phrase matcher \n",
    "from spacy.matcher import PhraseMatcher\n",
    "matcher = PhraseMatcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = list(nlp.pipe(COUNTRIES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add('COUNTRY', None, *patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "#call matcher on test doc and print results\n",
    "matches = matcher(doc)\n",
    "print([doc[start:end] for match_id, start, end in matches])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    FESTUS\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Miss.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " (FOX \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    13\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       ") - \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    One\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " café put a major twist on a classic ice cream sundae by introduced: pickle splits. \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    The Pine Mountain Country Coffee House\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Festus\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", </br>\n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Missouri\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " simply replaced the banana in a banana split with a pickle. The owner of the café said she \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    first\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
       "</mark>\n",
       " tried the combination back when she was younger. It started \n",
       "as a “dare” but she ended up liking it. CONTINUE READING BELOW It wasn’t until her husband teased her into putting it on the menu that her pickle passion was made \n",
       "public. The dish comes with vanilla, strawberry and chocolate ice cream. All topped with whipped cream, cherries and, of course, pickle spears.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(reg_d, style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
