{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING A NERUAL NETWORK MODEL "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when to use:\n",
    "    1. Essential- Text classification\n",
    "    2. Very useful- NER\n",
    "    3. Less critical- POS & Dependecy Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "process\n",
    "1. Initialize - nlp.begin_training\n",
    "2. Predict - nlp.update\n",
    "3. Compare\n",
    "4. Calculate\n",
    "5. Update\n",
    "6. revert to step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXTS = ['How to preorder the iPhone X',\n",
    " 'iPhone X is coming',\n",
    " 'Should I pay $1,000 for the iPhone X?',\n",
    " 'The iPhone 8 reviews are here',\n",
    " 'Your iPhone goes up to 11 today',\n",
    " 'I need a new phone! Any tips?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "from spacy.lang.en import English\n",
    "from spacy.matcher import Matcher\n",
    "nlp = English()\n",
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two tokens whose lowercase forms match 'iphone' and 'x'\n",
    "pattern1 = [{\"LOWER\": \"iphone\"}, {\"LOWER\": \"x\"}]\n",
    "\n",
    "# Token whose lowercase form matches 'iphone' and an optional digit\n",
    "pattern2 = [{\"LOWER\": \"iphone\"}, {\"IS_DIGIT\": \"x\", \"OP\": \"?\"}]\n",
    "\n",
    "# Add patterns to the matcher\n",
    "matcher.add('GADGET', None, pattern1, pattern2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to preorder the iPhone X [(4, 6, 'GADGET'), (4, 5, 'GADGET')]\n",
      "iPhone X is coming [(0, 2, 'GADGET'), (0, 1, 'GADGET')]\n",
      "Should I pay $1,000 for the iPhone X? [(7, 9, 'GADGET'), (7, 8, 'GADGET')]\n",
      "The iPhone 8 reviews are here [(1, 2, 'GADGET')]\n",
      "Your iPhone goes up to 11 today [(1, 2, 'GADGET')]\n",
      "I need a new phone! Any tips? []\n"
     ]
    }
   ],
   "source": [
    "# Create a Doc object for each text in TEXTS\n",
    "for doc in nlp.pipe(TEXTS):\n",
    "    # Find the matches in the doc\n",
    "    matches = matcher(doc)\n",
    "    \n",
    "    # Get a list of (start, end, label) tuples of matches in the text\n",
    "    entities = [(start, end, 'GADGET') for match_id, start, end in matches]\n",
    "    print(doc.text, entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### training with spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_DATA = []\n",
    "\n",
    "#create a Doc object for each text in TEXTS\n",
    "for doc in nlp.pipe(TEXTS):\n",
    "    #Match on the doc and create a list of matched spans\n",
    "    spans = [doc[start:end] for match_id, start, end in matcher(doc)]\n",
    "    \n",
    "    #get the start char, end char, label for tuples of matches\n",
    "    entities = [(span.start_char, span.end_char, 'GADGET') for span in spans]\n",
    "    \n",
    "    #format matches as a (doc.text, entities)  tuple\n",
    "    training_example = (doc.text, {\"entities\": entities})\n",
    "    \n",
    "    #append to training data\n",
    "    TRAINING_DATA.append(training_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('How to preorder the iPhone X', {'entities': [(20, 28, 'GADGET'), (20, 26, 'GADGET')]})\n",
      "('iPhone X is coming', {'entities': [(0, 8, 'GADGET'), (0, 6, 'GADGET')]})\n",
      "('Should I pay $1,000 for the iPhone X?', {'entities': [(28, 36, 'GADGET'), (28, 34, 'GADGET')]})\n",
      "('The iPhone 8 reviews are here', {'entities': [(4, 10, 'GADGET')]})\n",
      "('Your iPhone goes up to 11 today', {'entities': [(5, 11, 'GADGET')]})\n",
      "('I need a new phone! Any tips?', {'entities': []})\n"
     ]
    }
   ],
   "source": [
    "print(*TRAINING_DATA, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAINING LOOP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a blank 'en' model \n",
    "NLP = spacy.blank('en')\n",
    "\n",
    "#create a new NER \n",
    "ner = NLP.create_pipe('ner')\n",
    "nlp.add_pipe(ner)\n",
    "\n",
    "#add label \"GADGET\" to pipe\n",
    "ner.add_label(\"GADGET\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Building the training loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 6.51512819543863e-08}\n",
      "{'ner': 6.614709624369499e-08}\n",
      "{'ner': 6.652261900226123e-08}\n",
      "{'ner': 5.090853019817102e-11}\n",
      "{'ner': 5.329953295477475e-11}\n",
      "{'ner': 3.078630782480545e-10}\n",
      "{'ner': 3.4044795407430947e-13}\n",
      "{'ner': 3.642978338192603e-13}\n",
      "{'ner': 8.052305506719143e-13}\n",
      "{'ner': 3.598232994053063e-13}\n",
      "{'ner': 3.726822629527728e-13}\n",
      "{'ner': 4.631656761721895e-13}\n",
      "{'ner': 2.8713117779108397e-13}\n",
      "{'ner': 3.1756543163958325e-13}\n",
      "{'ner': 3.2242860418382725e-13}\n",
      "{'ner': 1.1053114014639007e-14}\n",
      "{'ner': 1.5802349161864956e-13}\n",
      "{'ner': 1.580777916356791e-13}\n",
      "{'ner': 3.1525596792589103e-15}\n",
      "{'ner': 8.240035998311857e-14}\n",
      "{'ner': 8.243964220871929e-14}\n",
      "{'ner': 4.8759706422508677e-14}\n",
      "{'ner': 4.883008463186351e-14}\n",
      "{'ner': 4.965230489658564e-14}\n",
      "{'ner': 2.1978362822724574e-14}\n",
      "{'ner': 2.265651490213919e-14}\n",
      "{'ner': 2.3190005199734364e-14}\n",
      "{'ner': 1.0213869019842861e-15}\n",
      "{'ner': 1.0356378779968938e-14}\n",
      "{'ner': 1.0402111820333674e-14}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "nlp.begin_training()\n",
    "\n",
    "#loop through training\n",
    "for itn in range(10):\n",
    "    #shuffle training data\n",
    "    random.shuffle(TRAINING_DATA)\n",
    "    losses = {}\n",
    "    \n",
    "    #batch examples together and iterate over them\n",
    "    for batch in spacy.util.minibatch(TRAINING_DATA, size=2):\n",
    "        \n",
    "        texts = [text for text, entities in batch]\n",
    "        annotations = [entities for text, entities in batch]\n",
    "        \n",
    "        #update model \n",
    "        nlp.update(texts, annotations, losses=losses)\n",
    "        print(losses)\n",
    "        \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
